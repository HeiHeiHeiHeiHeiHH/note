
PHP5.4之后有内置一个服务器（不能用与线上，无需构建本地服务）php -S HOST_IP -t 指定目录

递归： 自己调用自己，自己包含自己   function a( param b) { a(param c);} 属于函数内再次调用自己
      注意：1 递归是函数在过程中或函数里面调用自身
	    2 在使用递归时 必须要有一个明确的递归结束条件，成为递归出口
      两个阶段：1 递推：把复杂的问提的求解推到比原问题简单一些的问题的求解;
		2 回归：当获得最简单的情况后，逐步返回，依次获得复杂的解

迭代： 将输出做输入，再次进行处理。迭代次数越多，细节都越高（A 不停调用B）
 	递归忠一定有迭代，反之不然， 大部分可以相互转换，能用迭代的不用递归（递归效率有点低，浪费空间，并容易造成堆栈的溢出）


高阶函数： 最常见使用策略模式

call_user_func_array(callable $callback,array()) 调用回调，并把一个数组作为参数.
        也可以以对象静态方法作为callback， example : call_user_func_array(array('classname','func'),array(data));



Xdubug  代码调试工具（相比于echo print 等断点， 在不熟悉代码的情况下效率更高）默认端口9000 建议重置
    修改php.ini： [xdebug] xdebug.remote_port = ip_port
	记得xdebug的端口是否可用与重复  phpstrom内置web application端口问题等

依赖管理Composer与packagist
packagist 安装一般为pear(php-pear   使用现在较少)

composer .json文件配置说明  name : "所有者/包名"
			   description : "包描述  通常一句话"
			   keywords : "包作用关键字 利于检索"
       基本信息：	   homepage: "包主页或个人主页"
			   time :"发布时间"
			   license : 决定公开发布的许可证［MIT］
    			   authors : {作者数组，新名，邮箱，主页等信息}


	依赖管理：	  require : {组件对象， 所有者/包名 ： 版本号信息 等}

	开发依赖：	  require-dev: {}  开发环境使用组件  生产环境不需要使用.

 	自动加载：          Vendor/autoload.php  自动加载文件(Vendor外目录运用命名空间可以在这里添加)

			  config : 自定义Vendor目录位置    默认当前目录下

     			  repositories : {package位置、类型等}

			  scripts: 运行脚本  install scripts \ update scripts


                          自动添加包  composer require content 然后update

nowdoc与heredoc区别
  	nowdoc :   $test = <<<'EOD'
			AAAAAA.
			BBBBBBBBB.
			CCCCC.
			$sth DDDDDD.
		   EOD;    $sth不会以变量的形式所解析
	heredoc:   $test = <<<EOD
			    AAAAA.
			    BBBBBBB.
			    CCCC.
			    $sth DDDDD.
			   EOD;   $sth会被解析
	


 	现定义固定长字符串再输出会比直接输出多占用一倍的内存！！！！！！！


使用UTF8编码（未在底层实现怼Unicode的支持）
 	WEB应用从三个方面入手。1 HTML 2 SQL 3 PHP
 	PHP层面的使用：对于字符串操作（有些是不会影响的），如果该函数有mb_*扩展过的用法，使用mb_*。
		      或者脚本开头使用mb_internal_encoding()，然后在对浏览器输出的脚本中使用mb_http_output().
	另外：字符串操作如能指定指定编码集最好指定.

	数据层面：数据库设计时指定编码集为UTF8MB4。  并在链接数据库请求时也使用相同的编码集.

	浏览器层面：脚本输出使用mb_http_output()确保输出格式.
		    html head 标签指定页面编码<meta >中 Content-type charset

复杂语法： {$params}


满二叉树： 每个节点有且仅有两个字节点。


完全二叉树： 深度为K 有N个节点。 当且仅当其每个节点都与深度为K的满二叉树中序号为1至n的节点对应。


冒泡排序：   轮询两个，比较大小，交替位置。

快速排序：   以任一元素作为基准，对比分为两个区域，比他大的与小的，递归的排寻出两个分区。 组合

归并：       分治法  将问题分解， 子问题的解的合并即问题的解。
	    
堆排序：    最大堆与最小堆。 
	    首先：对数据进行依次二叉排 找出最大或最小。  然后进行递归。

选择排序：   不是稳定的排寻算法， 数据大时， 因为可能交换操作的原因，占用较大的CPU。 n小的时候比冒泡快
	    时间复杂度O(n2);

插入排序：   假定有一个子序列已经排序完成。 将后续与之比较，并运行。
 
希尔排序：   首先分组进行插入排序， 在分组插入排序， 最后重组。(d1 => n/2,d2 => d1/2,d3 = d2/2 ...1）


打开文件读的方法：
      1 fopen($file, "r+a")  打开一个文件或url. 返回一个对文件本身的引用
		当mode为w时　　默认是会清空文件的　若不清空　直接用追加模式a 或者 w+a 
        feof($fp) 参数：文件引用。 判断是否读取到文件的最后。
        fclose($fp)  关闭文件引用 释放资源
        fgets($fp, $font-size)  获取文件中的一行内容， 不会超过font-size的大小。  适用读取文本型文件
	freads($fp,$bytesize)   读取二进制文件， 因二进制文件没有行的概念必须指定$bytesize(max 8Kb)

      2 跳跃访问： fseek($fp, 0 ,$pose);


文件写方法：
	fopen($file, "w+a")
	fwrite($fp,$data);
	fclose($fp);

xml结构
     <?xml version="1.0"  encoding="字符编码" ?>
     有且仅有一个最顶层节点 类似余html中 <html></html>
        中间包含任一标签节点。  注意闭合。
    

grep : 查找文件或命令结果中匹配表达式命中的行结果 。 
     grep -i  忽略表达式大小写的形式
     grep -r/-R  递归的在某个中的所有文件查询  -h 禁止文件路径的显示
     grep -w  返回包含指定表达式的结果。  -c   返回命中的次数   -n 命中目标的所在行数  
	  -v  反转匹配（不匹配）  -l 返回包含匹配式的文件


shell_exec($shell_command)    返回值：命令执行结果。

取地址符&:   php中&符号的含义为一个变量或函数或对象的别名。 当建立别名后不管是unset(别名or原量)都只是删除了他们之间的别名链接。并没有删除原有的地址空间，内容还存在。 在函数中使用别名引用变量， 若在函数内别名值改变， 对应的原量也会改变（毕竟指向同一内存空间）。  此时使用函数是不可在别名位置传递常量。因为只有变量才能被引用。

date()时间格式'Y-m-t'：  返回当月的最后一天。

getopt():  从命令行参数列表中获取选项。 ex: $data = getopt($options,$longopts,$optind)
           $options:  单个字符a-zA-Z0-9: . 参数传递时：-a-zA-Z0-9=value;
	   $longiots: 选项数组。 每个元素会被最为选项字符串。  匹配：--string=value;

array_shift($array):  移出数组$array中的第一个素。 返回第一个元素的值.

array_diff($arr1,$arr2) : 计算数组的差值。  

list($param1, $param2 ...) = array($value1,$value2 ...) 注意list()不是真真意义的函数而是一种语言结构，将数组的至分配至相应的变量中去  

urlencode(): 将中文字符转换为urlencode格式，数字、阿拉伯字符不会被转换

http_build_query():将数组中的键值转换为http请求中的数据请求格式。

array_chunk($array,$size): 将数组分隔为多个数组，数组大小为size



RPC 远程调用服务(Remote Procedure Call Protocol)：成熟框架Thrift、duddo等。（JUMEI：PHP-CLIENT）
   1  本地客服端以本地调用服务的方式调用远程服务。
   2  客服端rpc服务接受到调用后将方法、参数等信息封装成能够进行网络传输的消息体。
   3  找到相对应的服务地址后，将信息加密传输至服务端。
   4  服务端接受消息后解密。
   5  根据解码信息调用server上的本地服务
   6  执行并将结果返回给server
   7  server将结果打包加密发送至消费方
   8  client接受消息解密。
   9  服务方获取最终结果.
     RPC的目标是对2-8的封装。
         难点  1  消息体的序列化与反序列化（加密解密二进制，毕竟网络通信）
               2  明确规范消息数据结构
	       3  通信。  通信模型：BIO，NIO  需都支持.
		  BIO通信方式： 没一个请求添加一个进程，当进程达到上限时，后续请求将会排队等待（同步阻塞？？？？？？？？）
  		  NIO通信方式： 分而治之。尽可能的任务分细，让每个进程都能满载和满效率的使用。
			主要分为：mainReactor线程负责监控server_socket,accept新链接。subReactor负责多路分离已链接的socket（可以单一进程，可以进程池，取决于CPU核数），做后worKer。

   	       4  如何确保客服端所接受的返回信息是自己所需要的结果。
		    1 客服端请求RPC服务是产生一个基于当前socket的唯一uid.
		    2 对于请求结果调用回调函数，存放到全局方法中，根据uid处理
 	            3 对于回调函数中，当前进程试图使用uid获取返回结果，如无则等待。 回调锁？ 什么鬼？
		   

mcpd: redis本地连接池。


聚美RPC服务使用：
	对于业务构建RPC服务： 继承与JMRpcServer类。 建立相应的入口文件。
			     建立AuthClient认证文件夹： 继承JMRpcServerAuthClientUser()验证Secret,设定可以访问的类与方法   规范 filename_classname::methodname/* 。 建立相应的文件与类文件。 写入绑定的方法，给定参数，运行，返回运行结果。


	使用：   根据PHPClient组件中的Config文件。  配置所需调用的rpc服务


对于apt安装软件包：
  apt-cache search packagename 搜索指定名称的软件包
  apt-cache show packagename 获取相关包的相关信息
  apt-get install package  安装软件包
  apt-get install package --reinstall 重新安装
  apt-get -f install 修复安装 -f == --fix-missing
  apt-get remove package 卸载一个已安装的软件包（保留配置文件）
  apt-get check 检查是否有已损坏的依赖
  apt-get remove package --purge 删除包包括配置文件等
  apt-get update 更新源
  sudo apt-get upgrade 更新已安装的包
  apt-get dist-upgrade 升级系统的内核
  apt-get dselect-upgrade 升级方式为dselect
  apt-get build-dep package 安装相关的编译环境
  apt-get source package 下载软件包源代码
  apt-get autoclean  已转已卸的软件备份至硬派
  apt-get clean && autoclean 清理无用的包
  apt-cache depends package 了解使用依赖
  apt-cache rdepends package 查看该包被那些包依赖
  apt-cache dumpavail 打印可用软件包列表
  dpkg -L package 列出软件包中的所以文件
  dpkg -force-all --purge packagename 卸载难以卸载的软件
  dpkg -I package-name-pattern  
  



对于hg版本控制 当没有merge提交至中心代码库时  中心代码库主干分支并没有该次提交的代码记录。
只保存有该次提交的日志记录（感觉只是做了一次快照） 别的分支讲道理获取不到这次的修改集 
想获取：（个人认为） hg log 查看属于该次提交的提交版本号 
		     hg export 版本号 -o 输出至一个文件
		     hg import 文件名  获取修改集 
		     hg rollback && hg st 查看获取的修改 检查是否所需

开新分支的时候， 注意基于主分支的分支版本是否是最新的代码。 不仅是做一次hg pull default -b default就好，需要一次hg up操作来将本地主干分支代码拉去到最新的位置。


对于一个入口文件： 基础功能主要在于定义一些常量，项目路径，路由方法，是否开启调试模式等信息 

对于接口类： 一个类可以继承多个接口逗号分隔 使用过程中通过interfaceof判断
所调用的类是否与需对应类有联系

类复用（trait）：单继承语言代码复用机制 开发者能在不同的层次结构中复用同一个类中的
的方法。 使用：采用use关键字   一个类中可使用多个复用类   逗号分隔。
优先级：基类继承的成员会被trait中出入的成员所覆盖。当前类成员覆盖了trait的方法
，而trait则覆盖了被继承的方法。
多个trait存在相同方法冲突的解决：1 可以使用insteadof操作符指定使用那个冲突方法
2 as操作符引入某个方法的别名。


因为nginx服务器在服务器问题是不会输出错误的信息不易调试
   采用PHP自带的模拟服务器 php -S address:port 会报出错误信息与位置.


PHP多进程与多线程只能运行在cli模式下.
  多进程pnctl扩展（unix环境）:  通过fork机制。 pnctl_fork() 从当前位置生成一个子进程。 子进程的堆栈信息从父进程中完全复制的。 所以fork之前的变量信息子进程也不是使用。返回值0 ，-1 ，pid
    0 ： fork成功。产生一个子进程。当需循环fork子进程是子进程结束必须exit()  -1 : fork失败  > 0 : 父进程
    僵尸进程：当子进程退出后，父进程没有及时回收，保留了子进程的执行状态 
    串行：在需要循环fork进程时，一般情况下必须等待子进程功能结束后在进行新的fork。 通过pnctl_wait($status)获取子进程的执行状态(父进程）。
    并行：循环fork进程时。 通过pnctl_waitpid()  并添加参数WNOHANG, 无需等待子进程的返回状态 直接跳过 进行后续fork 达到并行处理。


FLUME：运行的3种模式  
    Exec Source 直接运行 采用unix command的方式组织数据 快速数据完整性不能保证 单是实时性强
    Spooling Dirctory SOurce 监测配置的目录下新增的文件  同样有限制 实时性比较强 但是数据完整 限制：1 拷贝到spool下的文件不可以在编辑 2 不可包含相应的子目录
    Channel方式：MemoryChannel, JDBC Channel ,MemoryRecoverChannel, fileChannel.

    memoryChannel可以实现高速的吞吐，但是无法保证数据的完整性
    MemoryRecoverChannel使用filechannel代替
    filechannel保证数据完整性和一致性，不过吞吐慢与memorychannel
    
    核心概念：
	agent:代理 一个机器只有一个agent 可以有多个sources和sinks
     	Client:生产数据，运行在一个独立的线程
	Source:从client收集数据，传递给channel
 	sink:从channel中收集数据 运行与一个独立的线程
	channel: 连接source和sinks 数据中间缓存
 	Events:可以是日志记录、avro对象等

    将数据推到hdfs时， 在hadoop中重新建立一个新的节点存储
    使用：在conf中编辑想应的agent、channel、sinks信息
      运行：/bin/flume-ng agent --conf ../conf -f /path/conf.conf -n agentname -Dflume.root.logger=INFO,console  最后一项为调试模式


查看占用端口的进程： sudo lsof -i:port

查看进程是否存在: shell: kill -0 $pid 存在返回0 不存在返回1
		  php: posix_kill($pis, 0) 存在true

hive表查看分区信息： show partitions table_name;

自动加载类的实现：
     1 定义两个初始的根目录（项目根目录与vendor根目录,vendor根目录是为了加载使用的组件）
     2 添加根目录的路径（最好是绝对路径)
     3 使用spl_autoload_register()函数加载命名空间
       spl_autoload_register($autoload_callback,$throw,$repend): $1 : 使用回调函数加载 若为空 则使用默认函数注册sql_autoload()
     4 加载  使用3注册的回调函数进行加载
       一般过程 获取类所在的命名空间如: \Module\Text
       转换命名空间为相应的路径： str_replace('\\' , '/', "\Module\Text")
       搜索每个根目录下是否含有/Module/Text.php 文件 存在 require_once  并判断是否含有该类class_exists("\Module\text",false) 存在return true
        

在源码中查找某个函数的c语言实现：
    查找: grep -rn "PHP_FUNCTION(function_name)" ./php-src/ext/   会返回定义该函数的.h文件路径和实现的.c路径


读取文件流中内容:fgets,fread,file_get_contents(); 都很快  = = 慢的是处理获取的内容 file_get_contents() 依次处理所有获取到的内容 另外两个可想～

重置mysql中自增列的重新计数: TRUNCATE TABLE_NAME;

关于try catch :当try中的执行的代码段出现异常（这里有很多情况）时，而不是什么语句没有执行成功等等。 执行catch模块。

关于事务：事务的特性：1 原子性(要么都执行，要么都不执行) 2 一致性（状态一致性） 3 隔离性(并发情况下的解决。首先是一个事务执行前的锁表操作，使得其他事务事件不会操作相同的事物表，牺牲一定的处理效率) 4 持久性(事务完成怼系统的营销是永久的）     （succss or faith）

异步与同步: 关注点为消息通信机制。
  同步： 发出请求后，在没有得到返回时 该请求没有返回，请求处理返回结果后，请求能获得返回值： 请求主动等待请求处理结果
  
  异步： 发出请求直接返回。请求不会立即获得处理结果，而是处理结束后通过回调等方式通知请求.

阻塞与非阻塞： 关注点为程序等待调用结果时的状态.
    阻塞是当前的请求进程会被挂起，直到得到请求的处理结果。
    非阻塞是不会等待请求的处理结果，可以去做其他的请求， 不过需要隔段时间去检查该次请求的结果是否返回。


php socket: 
    socket_set_block 设置为阻塞模式 所以我特么读不到！！！
    socket_set_noblock 非阻塞！！！！！！



PHP STREAM函数:
    set_socket_blocking:stream_socket_blocking的别名，将该资源的读写方式设置为阻塞.
    stream_context_create(array $options,array $params): 创建资源流上下文。
       $options:必须为二维关联数组 默认为空数组
       $param: 必须为关联数组.
       example: $opts = array(
		  "http" => array(
		    "method" => "POST",
		    "HEADER" => "....."
		  )
		); $context = stream_context_create($opts); $fp = fopen("http://www.example.com","r",$context);
    


    对于阻塞的send：首先需要将数据写入到缓冲区中， 当缓冲区中的空间不够是会继续等待有足够的空间时返回.对于非阻塞 没有空间直接返回一个没有空间的状态回来.
    对于recv:如果缓冲区中的没有给予一个接受完成的状态它将一直保存receive状态，非阻塞相反。 
    
    对于阻塞的server：如何读取缓冲区的内容。 
         socket_set_block($socket_resource):  socket_recv($resource, $recvData, $length, MSG_EOL); 设置length大小。 MSG_EOL读到结束标志位或者最大长度也就是length。判断接受到的长度是否小于length. 小于则数据已读完。进行以后的操作了. 反之则继续读！！！


    测试代码（万能的）：register_shutdown_function(function () { var_dump(error_get_last());};

数据库链接池：  首先有使用直连or连接池的开关。
	每个链接的还是为长链接。 开启默认的链接数量。有最大的链接数量限制。 这会有定期的心跳机制检测。 链接断开时重启 保持一定的链接数量
	
  	同一个链接对象 不管是mysql or redis 
  	
	将对象保存栈中， 每次有连接请求时 从栈中取出一个已开启的链接 剩余栈中的为剩余可连接数量 如栈中没有且为达到最大的链接数量 则重新建立一个新的链接 若已为最大链接则等待 这里可以有个通知机制
	当无可用链接时一直等待 若等待时间超过默认时间时返回链接超时 有可用时将通知


 魔术方法：__get()、__set() 将对象的属性接管 需手动添加到类中
	  
    example: __set($name,$value)   $obj->$name = $value  Get: $obj->value;

	__call, __callStatis 控制对象的方法/静态方法的调用
	当调用的方法不存在是产生错误，可以使用__call方法避免 
        当调用不存在的静态方法时 使用__callStatic (需使用public static 申明)

  	__toString 将对象转换为字符串

	__invoke 将对象当成函数 (5.3.0以上版本有效)
	__isset() 当对不可访问属性调用isset或empty时调用  当类外部使用isset时调用
	__unset（）同上 相反的意思

	__sleep() 执行serialize()时 会先调用这个函数
	类外部使用serialize时使用

	__wakeup() 执行unsialize()时 

	__debugInfo() 打印所需调试的信息 PHP VERSION >= 5.6.0 
	
	__autoload() 尝试加载未定义的类 定义这个函数来启用类的自动加载

	__clone() 当对象复制完成是调用

   postfix 邮件服务命令
       mailq 显示待寄邮件的清单 mailq [-q] -v 显示详细信息

       postsuper -d 邮件编号/ALL 请求队列(所有时,ALL必须大写)
       
       queueger 可以删除指定ID号的队列邮件

       postqueue -p 查看队列内容

       postqueue -f 将寄存队列的邮件重新发送一遍
 
       postcat 查看队列中的邮件内容

       postsuper -d ALL hold/deffered... 删除某个队列里的所有邮件

  redis事务中不支持的类型：keys|BLPOP|MSETNX|BRPOP|RPOPLPUSH|BRPOPLPUSH|SMOVE|SINTER|SINTERSTORE|SUNION|SUNIONSTORE|SDIFF|SDIFFSTORE|ZINTER|ZUNION|FLUSHDB|FLUSHALL|RANDOMKEY|SELECT|MOVE|RENAMENX|DBSIZE|BGREWRITEOF|SLAVEOF|SAVE|BGSAVE|LASTSAVE


   hadoop配置好后启动： sbin/start-dfs.sh   sbin/start-yarn.sh  bin/hdfs namenode
   配置文件配置：/etc/hadoop/yarn-site.xml  /etc/hadoop/hdfs-site.xml

   获取浏览器的hadoop服务:http://localhost:50070/
   验证集群中的所有应用程序:http://localhost:8088/

   hive配置：/hive/conf/ cp hive-env.sh.template hive-env.sh 添加export HADOOP_HOME=/hadoopdir

   配置hive的metastor配置： /hive/conf/hive-site.xml
     追加：<property>
		<name>javax.jdo.option.ConnectionURL</name>
		<value>jdbc:derby://localhost:1527/metastore_db;create=true</value>
		<description>JDBC connect string for a JDBC metastore</description>
	   </property>

   创建jpox.properties文件，追加：
     javax.jdo.PersistenceManagerFactoryClass =

org.jpox.PersistenceManagerFactoryImpl
org.jpox.autoCreateSchema = false
org.jpox.validateTables = false
org.jpox.validateColumns = false
org.jpox.validateConstraints = false
org.jpox.storeManagerType = rdbms
org.jpox.autoCreateSchema = true
org.jpox.autoStartMechanismMode = checked
org.jpox.transactionIsolation = read_committed
javax.jdo.option.DetachAllOnCommit = true
javax.jdo.option.NontransactionalRead = true
javax.jdo.option.ConnectionDriverName = org.apache.derby.jdbc.ClientDriver
javax.jdo.option.ConnectionURL = jdbc:derby://hadoop1:1527/metastore_db;create = true
javax.jdo.option.ConnectionUserName = APP
javax.jdo.option.ConnectionPassword = mine

    declare: 接受两种参数。 ticks 或 encoding.
 	ticks 当执行n条低级指令时， 调用所注册的方法。 注：条件语句与判断语句一般不算低级指令。
        encoding: 接下来执行的代码的编码是指定的编码.

    使用共享内存进行通信：  使用ftok()函数建立一个共享内存空间。
	shmop_open($shm_key, 'c/a/w/n','mode','size'): 打开一个共享内存
	shmop_read($shm_id, 'start', 'count'): 读取  start 开始位置 count  读取的长度
 	shmop_write($shm_id, 'data', 'offset'): 写入 
	shmop_close($shm_id): 关闭 不会删除共享内存 清除php的缓存
	shmop_delete($shm_id): 输出共享内存块
	shmop_size($shm_id):共享内存中的数据长度.

    对共享内存的加锁机制：  使用ftok()函数建立一个共享内存的key
	sem_get($key): 获取一个信号量资源 $sem_id
	sem_acquire($sem_id): 获取信号
	sem_release($sem_id): 释放资源
	sem_remove($sem_id): 把这次信号量从系统中移除
    
    消息队列： 创建一个消息队列区 ftok(__FILE__, 'm') $id
	msg_get_queue($id):获取消息队列生成 $msg_id
	msg_send($msg_id, "MSG_TYPE",$message): 先队列中推送消息
	msg_receive($msg_id,"MSG_TYPE",$msgtype, 'size', $message): 获取队列中的消息，$message
        
        队列机制只能有一个进程能获取或写数据 所以不需要额外的锁或者信号量.

    信号：主要通过posix_kill($pid, $signal)向指定的进程传递一个信号量。该进程调用所注册的信号处理函数处理
	
    管道：两种有名管道与无名管道， 无名管道只能在具有亲缘关系的进程之间使用，有名管道则在同一物理机上的所有进程都可通行。
	$pipe_path = "/path/to/file.pipe":定义管道路径
	判断路径文件是否存在，不存在则posix_mkfifo($pipe_path, '0777')创建管道 return boolean
	
	向管道中写数据：$file = fopen($pipe_path，'w'); fwrite($file, $data); 需要关闭吗？？？？？
	读取：$file = fopen($pipe_path, 'r'); fread（$file,$size); 
	单向的， 传递的数据是无格式的数据流.

    socket:



   UDP协议：将数据及源、目的封装在数据包中，不需要建立链接；每个数据包的大小限制在64k以内; 因无连接，是不可靠的;不需要建立连接，所以传输速度快，但容易丢包.

   实现：传输基于Datagramsocket与dataframpacket; 建立发送端与接受端;建立数据包;调用socket的发送接受方法；关闭套接字;发送端和接受端是两个独立的运行程序.

   服务端：stream_socket_server("udp://host:port",$errno, $error):建立
	   stream_socket_sendto($socket, $data, 0, $adderr):发送
	   stream_socket_recvfrom($socket, $length, 0, $address):接受

   服务端：stream_socket_client("udp://host:port",$errno, $error):建立 获取句柄
	   fwrite($hanlder, $data): 写
	   fread($hanlder, $length): 读
	   fclose($hanlder): 关闭


   引入composer包时产生的自动加载累， 如何引入我们自己写的？
	composer.json 文件中autoload字段中载入相对路径：path/file.php 或 classmap:相对路径 加载该路径下的 或者采用psr-0规范
	psr-0: autoload下添加字段psr-0:{"命名空间": "path/"} 对应 \path\命名空间\下的类文件
	psr-4: autoload下添加字段psr-4:{"命名空间":"path"}

	添加完成后还需执行composer dump-autoload  如果默认下载的会从国外的镜像中下载速度会很慢 可以在composer global config 中设置成国内镜像 会快很多.


 	并行与并发： 并行是指两个或多个时间在同一时刻发生;并发是指两个或多个事件在同一时间间隔发生。 并行是在不同实体上的多个事件;并发是在同一个实体上的多个事件a


	指定用户执行脚本：sudo -H -u username bash -c "执行命令"

	日志实现（monolog) 根据配置读取写日志的地址及一些开关 日志方式两种：文本日志，通过udp通信方式传递到指定地址（接受处理再报警）
	设定日志的等级及抛出异常的机制（差不多都继承与标准异常类）
	
	获取redis中的内存分布:
		1 获取redis当前的快照文件 dump.rdb
		2 下载sqlite数据库
		3 将快照文件转换成csv文件	rdb -c memory dymp.rdb > memory.csv
		4 创建数据库	sqlite3 memory.db 
		5 根据csv文件创建数据库表 create table memory(....)
		6 创建导入模式	.mode csv memory
		7 将文件中的内容导入到数据库	.import memory.csv memory

	c语言指针加减运算只针对数组指针 其他指针类型是不支持的(或者错误运算)
    
	当函数需要返回数组时. 必须已指针的类型返回 (返回数组的首地址,意味着只能已指针地址的形式传递信息, 和很过语言的区别很大 有点头大这地方. 同时函数类型也需申明为某某类型的指针, 接受函数返回值的地方也必须是一个指针变量 - - 存在地址的只能是指针变量 谋解)
	C语言的库文件 一般在/user/include  /user/local/include 目录下
	下载库文件的方法: 


	有关指针的数据类型的小节:
		int i:	定义整形变量i
		int *p: 定义一个指向整形数据的指针变量p
		int a[n]: 定义一个存放整形数据的数组a 数组长度为n
		int *p[n]:定义指针数组p, 由n个指向整形的指针元素组成
		int (*p)[n]: p为一个指向n个以为数组的指针变量
		int f(): 定义一个返回整数的函数f
		int *p(): p为一个返回指针的函数, 指针指向整形数据
		int (*p)(): p为指向函数的指针, 该函数必须返回一个整形数值
		int **p: p是一个指针变量,指向一个整形数据的指针变量
	

	void指针变量  定义一个指针变量 但不指定它指向的是那种数据类型

	结构体:
		格式: struct 结构名
			  {成员表列};
		example :
			struct stu
			{
				int num;
				char name[20];
				char sex;
				float score;
			};	
		说明方式:
			1 先定义结构再说明结构变量
			  struct xxx {......}; struct xxx param1,param2;
			  也可以用宏先表示一个结构类型
			  #define STU struct stu
			  STU
              {
				....
			  };

			  STU param1,param2;
			2 在定义结构类型的同时说明结构变量
			  struct xxx { ....} param1, param2;

		    3 直接说明结构变量
			  struct {....} param1, param2 ...;
		    可以嵌套使用的哦

			赋值: name.chengyuan = '';
			初始化:结构变量定义时: param={xxx,xxx,xxxx,....};

			结构数组的定义:将结构变量类型申明为一个数组就ok.
			遍历通过指针 能节省开销

	gcc编译过程：
		1 预处理阶段　根据源码的预处理语句　将包含的内容插入到源程序中生成．i文件　　gcc -o test.i -E test.c
		2 编译阶段　　将源码编译成为汇编文件.s　gcc -o hello.s -S hello.i
		3 汇编阶段　编译成机器语言.o文件　gcc -o hello.o -c hello.s
		4 连接阶段　gcc -o test test.s
		
		源文件－－>预处理－－>编译/优化－－>汇编－－>链接-->可执行文件。

	清空屏幕的函数为：system("clear"); h文件：stdlib.h   二进制文件打开hexdump
	
	
	
	
	declare(ticks = N) 与 pcntl_alarm() 闹钟处理   declare 没执行N条低级指令（也就是N行代码) 执行所注册的函数后再继续
    闹钟处理， 没执行一条指令就会检测是否有闹钟信号的到来 来了就执行然后再继续.(进程内有效)  
